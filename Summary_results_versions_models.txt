


v1 = uses leave one out, and then averages across the maximum criterion from each loo subsample.
v2 = uses full dataset to optimize epsilon


When the training model optimized epsilon was fit to each individual, recall was calculated, then averaged over the 12 individuals, for each of the different models, using the different quantile values in the training detector and testing detector.

            model recall.v1 recall.v2
1 <(vd-2),<(vd-2) 0.6666667 0.6666667
2    1:nT,<(vd-2) 0.6666667 0.6666667
3     <pw,<(vd-2) 0.6666667 0.6666667
4    >=pw,<(vd-2) 0.5833333 0.5833333
5     <(vd-2),<pw 0.7500000 0.7500000 *
6        1:nT,<pw 0.7500000 0.7500000 *
7         <pw,<pw 0.6666667 0.7500000
8        >=pw,<pw 0.5833333 0.6666667

Here's the different epsilon values we get for each of these models too:

> epsilon.v1.df
   <(vd-2),<(vd-2) 1:nT,<(vd-2) <pw,<(vd-2) >=pw,<(vd-2) <(vd-2),<pw 1:nT,<pw <pw,<pw >=pw,<pw
1             0.14         0.14        0.13         0.12        0.14     0.14    0.13     0.12
2             0.15         0.10        0.10         0.15        0.15     0.10    0.10     0.15
3             0.08         0.14        0.10         0.13        0.08     0.14    0.10     0.13
4             0.06         0.07        0.11         0.13        0.06     0.07    0.11     0.13
5             0.14         0.11        0.09         0.01        0.14     0.11    0.09     0.01
6             0.05         0.12        0.06         0.01        0.05     0.12    0.06     0.01
7             0.10         0.15        0.09         0.12        0.10     0.15    0.09     0.12
8             0.14         0.13        0.10         0.14        0.14     0.13    0.10     0.14
9             0.07         0.08        0.06         0.15        0.07     0.08    0.06     0.15
10            0.15         0.14        0.12         0.10        0.15     0.14    0.12     0.10
11            0.11         0.06        0.01         0.06        0.11     0.06    0.01     0.06
12            0.10         0.14        0.13         0.12        0.10     0.14    0.13     0.12
13            0.13         0.09        0.15         0.03        0.13     0.09    0.15     0.03
14            0.14         0.05        0.10         0.07        0.14     0.05    0.10     0.07
15            0.12         0.08        0.07         0.12        0.12     0.08    0.07     0.12
16            0.05         0.02        0.05         0.04        0.05     0.02    0.05     0.04
> epsilon.v2.df
   <(vd-2),<(vd-2) 1:nT,<(vd-2) <pw,<(vd-2) >=pw,<(vd-2) <(vd-2),<pw 1:nT,<pw <pw,<pw >=pw,<pw
1             0.14         0.15        0.13         0.13        0.14     0.15    0.13     0.13
2             0.15         0.10        0.11         0.15        0.15     0.10    0.11     0.15
3             0.08         0.15        0.10         0.13        0.08     0.15    0.10     0.13
4             0.06         0.07        0.11         0.13        0.06     0.07    0.11     0.13
5             0.15         0.11        0.10         0.01        0.15     0.11    0.10     0.01
6             0.05         0.13        0.07         0.01        0.05     0.13    0.07     0.01
7             0.11         0.15        0.10         0.12        0.11     0.15    0.10     0.12
8             0.14         0.13        0.10         0.14        0.14     0.13    0.10     0.14
9             0.07         0.09        0.06         0.15        0.07     0.09    0.06     0.15
10            0.15         0.14        0.12         0.10        0.15     0.14    0.12     0.10
11            0.12         0.07        0.01         0.07        0.12     0.07    0.01     0.07
12            0.10         0.14        0.13         0.12        0.10     0.14    0.13     0.12
13            0.13         0.09        0.15         0.03        0.13     0.09    0.15     0.03
14            0.15         0.05        0.10         0.07        0.15     0.05    0.10     0.07
15            0.12         0.08        0.08         0.12        0.12     0.08    0.08     0.12
16            0.05         0.02        0.05         0.04        0.05     0.02    0.05     0.04
> epsilon.star.v1.df
   <(vd-2),<(vd-2) 1:nT,<(vd-2) <pw,<(vd-2) >=pw,<(vd-2) <(vd-2),<pw 1:nT,<pw <pw,<pw >=pw,<pw
1             0.14         0.15        0.13         0.13        0.14     0.15    0.13     0.13
2             0.15         0.10        0.11         0.15        0.15     0.10    0.11     0.15
3             0.08         0.15        0.10         0.13        0.08     0.15    0.10     0.13
4             0.06         0.07        0.11         0.13        0.06     0.07    0.11     0.13
5             0.15         0.11        0.10         0.01        0.15     0.11    0.10     0.01
6             0.05         0.13        0.07         0.01        0.05     0.13    0.07     0.01
7             0.11         0.15        0.10         0.12        0.11     0.15    0.10     0.12
8             0.14         0.13        0.10         0.14        0.14     0.13    0.10     0.14
9             0.07         0.09        0.06         0.15        0.07     0.09    0.06     0.15
10            0.15         0.14        0.12         0.10        0.15     0.14    0.12     0.10
11            0.12         0.07        0.01         0.07        0.12     0.07    0.01     0.07
12            0.10         0.14        0.13         0.12        0.10     0.14    0.13     0.12
13            0.13         0.09        0.15         0.03        0.13     0.09    0.15     0.03
14            0.15         0.05        0.10         0.07        0.15     0.05    0.10     0.07
15            0.12         0.08        0.08         0.12        0.12     0.08    0.08     0.12
16            0.05         0.02        0.05         0.04        0.05     0.02    0.05     0.04

A screenshot of plots of these are attached, along with each of the plots.


Then, if we use the training data sample to test the optimized epsilons, and caculate recall within 1 day, and 2 days of true parturition, heres the results: 

   Version           Model        Prop 1 Day        Prop 2 Day
1       v1 <(vd-2),<(vd-2) 0.666666666666667 0.833333333333333
2       v1    1:nT,<(vd-2) 0.666666666666667 0.916666666666667
3       v1     <pw,<(vd-2)              0.75 0.833333333333333
4       v1    >=pw,<(vd-2)              0.75 0.916666666666667
5       v1     <(vd-2),<pw 0.666666666666667 0.833333333333333
6       v1        1:nT,<pw 0.666666666666667 0.916666666666667
7       v1         <pw,<pw              0.75 0.833333333333333
8       v1        >=pw,<pw              0.75 0.916666666666667
9       v2 <(vd-2),<(vd-2) 0.666666666666667 0.833333333333333
10      v2    1:nT,<(vd-2)              0.75 0.916666666666667
11      v2     <pw,<(vd-2)              0.75 0.833333333333333
12      v2    >=pw,<(vd-2) 0.833333333333333                 1
13      v2     <(vd-2),<pw              0.75 0.916666666666667
14      v2        1:nT,<pw              0.75 0.916666666666667
15      v2         <pw,<pw              0.75 0.833333333333333
16      v2        >=pw,<pw 0.833333333333333                 1



> FP.df
   versions           model fp.summary
1        v1 <(vd-2),<(vd-2)         31
2        v1    1:nT,<(vd-2)         13*
3        v1     <pw,<(vd-2)         36
4        v1    >=pw,<(vd-2)         15
5        v1     <(vd-2),<pw         31
6        v1        1:nT,<pw         13*
7        v1         <pw,<pw         36
8        v1        >=pw,<pw         15
9        v2 <(vd-2),<(vd-2)         33
10       v2    1:nT,<(vd-2)         13*
11       v2     <pw,<(vd-2)         39
12       v2    >=pw,<(vd-2)         16
13       v2     <(vd-2),<pw         33
14       v2        1:nT,<pw         13*
15       v2         <pw,<pw         39
16       v2        >=pw,<pw         16

